"""
Taint Analysis Engine for Dynamic Analysis Agent

This module implements taint analysis to track the flow of untrusted data
through applications and identify potential injection points and data leakage.
"""

import re
import requests
from typing import List, Dict, Any, Set, Optional, Tuple
from urllib.parse import urljoin, urlparse, parse_qs, urlencode
# Using requests directly for HTTP operations

class TaintSource:
    """Represents a source of tainted data"""

    def __init__(self, source_type: str, location: str, data_type: str = 'string'):
        self.source_type = source_type  # 'user_input', 'file', 'database', 'network'
        self.location = location  # parameter name, file path, etc.
        self.data_type = data_type  # 'string', 'integer', 'binary', etc.
        self.trust_level = 0  # 0 = completely untrusted, 10 = trusted

class TaintSink:
    """Represents a sink where tainted data could cause security issues"""

    def __init__(self, sink_type: str, vulnerability_type: str, severity: str):
        self.sink_type = sink_type  # 'sql', 'html', 'command', 'file', 'header'
        self.vulnerability_type = vulnerability_type  # 'sqli', 'xss', 'command_injection', etc.
        self.severity = severity  # 'CRITICAL', 'HIGH', 'MEDIUM', 'LOW'

class TaintedData:
    """Represents a piece of tainted data flowing through the application"""

    def __init__(self, value: str, source: TaintSource, taint_id: str):
        self.value = value
        self.source = source
        self.taint_id = taint_id
        self.propagated_to: List[str] = []  # Where this data has flowed
        self.sanitized = False
        self.sanitization_method: Optional[str] = None
        self.validated = False
        self.validation_method: Optional[str] = None

    def mark_propagated(self, location: str):
        """Mark that this tainted data has propagated to a new location"""
        if location not in self.propagated_to:
            self.propagated_to.append(location)

    def mark_sanitized(self, method: str):
        """Mark that this data has been sanitized"""
        self.sanitized = True
        self.sanitization_method = method

    def mark_validated(self, method: str):
        """Mark that this data has been validated"""
        self.validated = True
        self.validation_method = method

class TaintAnalyzer:
    """Taint analysis engine"""

    def __init__(self, base_url: str):
        self.base_url = base_url
        self.tainted_data: Dict[str, TaintedData] = {}
        self.vulnerabilities: List[Dict[str, Any]] = []
        self.sources: List[TaintSource] = []
        self.sinks: List[TaintSink] = []
        self.data_flows: Dict[str, List[str]] = {}
        self._initialize_sources_and_sinks()

    def _initialize_sources_and_sinks(self):
        """Initialize common taint sources and sinks"""

        # Common taint sources
        self.sources = [
            TaintSource('user_input', 'GET parameters'),
            TaintSource('user_input', 'POST parameters'),
            TaintSource('user_input', 'cookies'),
            TaintSource('user_input', 'headers'),
            TaintSource('file', 'uploaded files'),
            TaintSource('file', 'configuration files'),
            TaintSource('database', 'user data'),
            TaintSource('network', 'external APIs'),
        ]

        # Common taint sinks
        self.sinks = [
            TaintSink('sql', 'sql_injection', 'HIGH'),
            TaintSink('html', 'xss', 'HIGH'),
            TaintSink('command', 'command_injection', 'CRITICAL'),
            TaintSink('file', 'path_traversal', 'HIGH'),
            TaintSink('header', 'http_header_injection', 'MEDIUM'),
            TaintSink('code', 'code_injection', 'CRITICAL'),
            TaintSink('xml', 'xxe', 'HIGH'),
            TaintSink('ldap', 'ldap_injection', 'MEDIUM'),
            TaintSink('xpath', 'xpath_injection', 'MEDIUM'),
        ]

    def analyze_request(self, url: str, method: str = 'GET', data: Dict = None,
                       headers: Dict = None, cookies: Dict = None) -> List[Dict[str, Any]]:
        """
        Analyze an HTTP request for taint propagation

        Args:
            url: Request URL
            method: HTTP method
            data: Request data
            headers: Request headers
            cookies: Request cookies

        Returns:
            List of discovered vulnerabilities
        """
        # Extract tainted data from request
        tainted_inputs = self._extract_tainted_inputs(url, method, data, headers, cookies)

        # Send request and analyze response
        try:
            response = requests.request(method, url, data=data, headers=headers, cookies=cookies, timeout=10)
            if response.status_code == 200:
                self._analyze_response(response, tainted_inputs)
        except Exception as e:
            pass

        # Check for data flow vulnerabilities
        self._check_data_flow_vulnerabilities()

        return self.vulnerabilities

    def _extract_tainted_inputs(self, url: str, method: str, data: Dict = None,
                               headers: Dict = None, cookies: Dict = None) -> Dict[str, TaintedData]:
        """Extract potentially tainted input data from the request"""
        tainted_inputs = {}

        # Extract from URL parameters
        parsed_url = urlparse(url)
        if parsed_url.query:
            params = parse_qs(parsed_url.query)
            for param_name, values in params.items():
                for value in values:
                    taint_id = f"url_param_{param_name}"
                    source = TaintSource('user_input', f'URL parameter: {param_name}')
                    tainted_data = TaintedData(value, source, taint_id)
                    tainted_inputs[taint_id] = tainted_data
                    self.tainted_data[taint_id] = tainted_data

        # Extract from POST data
        if data and method.upper() == 'POST':
            for key, value in data.items():
                if isinstance(value, str):
                    taint_id = f"post_param_{key}"
                    source = TaintSource('user_input', f'POST parameter: {key}')
                    tainted_data = TaintedData(value, source, taint_id)
                    tainted_inputs[taint_id] = tainted_data
                    self.tainted_data[taint_id] = tainted_data

        # Extract from headers (some headers can be user-controlled)
        user_controlled_headers = ['referer', 'user-agent', 'x-forwarded-for', 'x-custom']
        if headers:
            for header_name, header_value in headers.items():
                if any(uc_header in header_name.lower() for uc_header in user_controlled_headers):
                    taint_id = f"header_{header_name}"
                    source = TaintSource('user_input', f'Header: {header_name}')
                    tainted_data = TaintedData(header_value, source, taint_id)
                    tainted_inputs[taint_id] = tainted_data
                    self.tainted_data[taint_id] = tainted_data

        # Extract from cookies
        if cookies:
            for cookie_name, cookie_value in cookies.items():
                taint_id = f"cookie_{cookie_name}"
                source = TaintSource('user_input', f'Cookie: {cookie_name}')
                tainted_data = TaintedData(cookie_value, source, taint_id)
                tainted_inputs[taint_id] = tainted_data
                self.tainted_data[taint_id] = tainted_data

        return tainted_inputs

    def _analyze_response(self, response: requests.Response, tainted_inputs: Dict[str, TaintedData]):
        """Analyze the response for tainted data propagation"""
        content = response.text

        # Check if tainted data appears in response (potential XSS/reflection)
        for taint_id, tainted_data in tainted_inputs.items():
            if tainted_data.value in content:
                tainted_data.mark_propagated('response_body')

                # Check for XSS context
                if self._is_in_html_context(content, tainted_data.value):
                    self._report_vulnerability({
                        'type': 'reflected_xss',
                        'severity': 'HIGH',
                        'description': f'Reflected XSS: User input from {tainted_data.source.location} reflected in HTML',
                        'evidence': f'Tainted value: {tainted_data.value}',
                        'recommendation': 'Implement proper output encoding'
                    })

        # Analyze HTML for data flows
        self._analyze_html_content(content, tainted_inputs)

        # Check for tainted data in headers
        for header_name, header_value in response.headers.items():
            for tainted_data in tainted_inputs.values():
                if tainted_data.value in header_value:
                    tainted_data.mark_propagated(f'response_header_{header_name}')

                    if header_name.lower() in ['location', 'refresh']:
                        self._report_vulnerability({
                            'type': 'open_redirect',
                            'severity': 'MEDIUM',
                            'description': f'Open redirect vulnerability via {header_name} header',
                            'evidence': f'Tainted value in {header_name}: {tainted_data.value}',
                            'recommendation': 'Validate redirect URLs against whitelist'
                        })

    def _analyze_html_content(self, content: str, tainted_inputs: Dict[str, TaintedData]):
        """Analyze HTML content for data flow patterns"""
        # Look for forms that might propagate tainted data
        form_pattern = r'<form[^>]*action=["\']([^"\']*)["\'][^>]*>(.*?)</form>'
        forms = re.findall(form_pattern, content, re.DOTALL | re.IGNORECASE)

        for action, form_content in forms:
            # Check if form action contains tainted data
            for tainted_data in tainted_inputs.values():
                if tainted_data.value in action:
                    self._report_vulnerability({
                        'type': 'form_action_manipulation',
                        'severity': 'MEDIUM',
                        'description': 'Form action URL may be manipulated with user input',
                        'evidence': f'Form action: {action}',
                        'recommendation': 'Validate form action URLs'
                    })

            # Check for hidden inputs that might contain tainted data
            hidden_pattern = r'<input[^>]*type=["\']hidden["\'][^>]*value=["\']([^"\']*)["\']'
            hidden_inputs = re.findall(hidden_pattern, form_content, re.IGNORECASE)

            for hidden_value in hidden_inputs:
                for tainted_data in tainted_inputs.values():
                    if tainted_data.value in hidden_value:
                        self._report_vulnerability({
                            'type': 'hidden_field_manipulation',
                            'severity': 'LOW',
                            'description': 'Hidden form field contains user-controlled data',
                            'evidence': f'Hidden value: {hidden_value}',
                            'recommendation': 'Avoid storing sensitive data in hidden fields'
                        })

    def _is_in_html_context(self, content: str, value: str) -> bool:
        """Check if a value appears in an HTML context where it could cause XSS"""
        # Find the context around the value
        value_index = content.find(value)
        if value_index == -1:
            return False

        # Look for HTML tags nearby
        start = max(0, value_index - 50)
        end = min(len(content), value_index + len(value) + 50)
        context = content[start:end]

        # Check for dangerous contexts
        dangerous_contexts = [
            r'<[^>]*>',  # Inside HTML tags
            r'<script[^>]*>.*?</script>',  # Inside script tags
            r'<style[^>]*>.*?</style>',  # Inside style tags
            r'javascript:',  # JavaScript URLs
            r'on\w+\s*=',  # Event handlers
        ]

        for pattern in dangerous_contexts:
            if re.search(pattern, context, re.IGNORECASE | re.DOTALL):
                return True

        return False

    def _check_data_flow_vulnerabilities(self):
        """Check for vulnerabilities based on data flow analysis"""
        for tainted_data in self.tainted_data.values():
            # Check if unsanitized data reaches sensitive sinks
            if not tainted_data.sanitized and tainted_data.propagated_to:
                for location in tainted_data.propagated_to:
                    if 'sql' in location.lower():
                        self._report_vulnerability({
                            'type': 'sql_injection',
                            'severity': 'HIGH',
                            'description': 'Unsanitized user input reaches SQL operations',
                            'evidence': f'Data from {tainted_data.source.location} -> {location}',
                            'recommendation': 'Use prepared statements or proper escaping'
                        })
                    elif 'command' in location.lower() or 'exec' in location.lower():
                        self._report_vulnerability({
                            'type': 'command_injection',
                            'severity': 'CRITICAL',
                            'description': 'Unsanitized user input reaches command execution',
                            'evidence': f'Data from {tainted_data.source.location} -> {location}',
                            'recommendation': 'Avoid executing user input as commands'
                        })
                    elif 'file' in location.lower() and 'path' in location.lower():
                        self._report_vulnerability({
                            'type': 'path_traversal',
                            'severity': 'HIGH',
                            'description': 'Unsanitized user input reaches file operations',
                            'evidence': f'Data from {tainted_data.source.location} -> {location}',
                            'recommendation': 'Validate file paths and use whitelists'
                        })

    def _report_vulnerability(self, vuln: Dict[str, Any]):
        """Report a discovered vulnerability"""
        # Avoid duplicates
        for existing_vuln in self.vulnerabilities:
            if (existing_vuln.get('type') == vuln.get('type') and
                existing_vuln.get('evidence') == vuln.get('evidence')):
                return

        self.vulnerabilities.append(vuln)

    def trace_data_flow(self, start_url: str, max_depth: int = 3) -> List[Dict[str, Any]]:
        """
        Trace data flow through multiple requests

        Args:
            start_url: Starting URL for analysis
            max_depth: Maximum depth to follow data flow

        Returns:
            List of discovered vulnerabilities
        """
        visited_urls = set()
        urls_to_visit = [(start_url, 0)]  # (url, depth)

        while urls_to_visit:
            current_url, depth = urls_to_visit.pop(0)

            if current_url in visited_urls or depth >= max_depth:
                continue

            visited_urls.add(current_url)

            # Analyze current URL
            self.analyze_request(current_url)

            # Discover new URLs to follow
            try:
                response = requests.get(current_url, timeout=10)
                if response.status_code == 200:
                    # Extract links
                    link_pattern = r'href=["\']([^"\']+)["\']'
                    links = re.findall(link_pattern, response.text, re.IGNORECASE)

                    for link in links[:3]:  # Limit links to avoid excessive scanning
                        if not link.startswith(('http://', 'https://', 'mailto:', 'javascript:')):
                            full_url = urljoin(current_url, link)
                            if urlparse(full_url).netloc == urlparse(start_url).netloc:
                                urls_to_visit.append((full_url, depth + 1))

            except Exception:
                continue

        return self.vulnerabilities


def test_taint_analysis(base_url: str) -> List[Dict[str, Any]]:
    """
    Test for vulnerabilities using taint analysis

    Args:
        base_url: Base URL to test

    Returns:
        List of discovered vulnerabilities
    """
    analyzer = TaintAnalyzer(base_url)

    # Analyze main page
    vulnerabilities = analyzer.trace_data_flow(base_url)

    # Test with some common injection payloads
    test_payloads = [
        ("'", "SQL injection test"),
        ("<script>alert(1)</script>", "XSS test"),
        ("../../../../etc/passwd", "Path traversal test"),
        ("; cat /etc/passwd", "Command injection test"),
        ("javascript:alert(1)", "JavaScript URL test"),
    ]

    for payload, description in test_payloads:
        # Test via GET parameters
        test_url = f"{base_url}?test={payload}"
        analyzer.analyze_request(test_url)

        # Test via POST data
        analyzer.analyze_request(base_url, method='POST', data={'test': payload})

    return analyzer.vulnerabilities
